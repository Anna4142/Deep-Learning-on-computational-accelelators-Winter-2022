digraph {
	graph [size="204.9,204.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2306910030640 [label="
 (1, 3, 80, 80, 85)" fillcolor=darkolivegreen1]
	2306562739312 [label=CloneBackward0]
	2306562739408 -> 2306562739312
	2306562739408 [label=PermuteBackward0]
	2306562737488 -> 2306562739408
	2306562737488 [label=ViewBackward0]
	2306562736816 -> 2306562737488
	2306562736816 [label=AddBackward0]
	2306562739840 -> 2306562736816
	2306562739840 [label=CudnnConvolutionBackward0]
	2306562785344 -> 2306562739840
	2306562785344 [label=SiluBackward0]
	2306562785776 -> 2306562785344
	2306562785776 [label=CudnnBatchNormBackward0]
	2306562786064 -> 2306562785776
	2306562786064 [label=CudnnConvolutionBackward0]
	2306562786880 -> 2306562786064
	2306562786880 [label=SiluBackward0]
	2306562788992 -> 2306562786880
	2306562788992 [label=CudnnBatchNormBackward0]
	2306562787120 -> 2306562788992
	2306562787120 [label=CudnnConvolutionBackward0]
	2306562785824 -> 2306562787120
	2306562785824 [label=SiluBackward0]
	2306562786016 -> 2306562785824
	2306562786016 [label=CudnnBatchNormBackward0]
	2306562785968 -> 2306562786016
	2306562785968 [label=CudnnConvolutionBackward0]
	2306562788272 -> 2306562785968
	2306562788272 [label=SiluBackward0]
	2306562787696 -> 2306562788272
	2306562787696 [label=CudnnBatchNormBackward0]
	2306562787600 -> 2306562787696
	2306562787600 [label=CudnnConvolutionBackward0]
	2306562787984 -> 2306562787600
	2306562787984 [label=SiluBackward0]
	2306562788416 -> 2306562787984
	2306562788416 [label=CudnnBatchNormBackward0]
	2306562786784 -> 2306562788416
	2306562786784 [label=CudnnConvolutionBackward0]
	2306562785392 -> 2306562786784
	2306562785392 [label=SiluBackward0]
	2306562787936 -> 2306562785392
	2306562787936 [label=CudnnBatchNormBackward0]
	2306562785872 -> 2306562787936
	2306562785872 [label=CudnnConvolutionBackward0]
	2306562786352 -> 2306562785872
	2306562786352 [label=CatBackward0]
	2306562787168 -> 2306562786352
	2306562787168 [label=UpsampleNearest2DBackward1]
	2306562789184 -> 2306562787168
	2306562789184 [label=SiluBackward0]
	2306562789040 -> 2306562789184
	2306562789040 [label=CudnnBatchNormBackward0]
	2306562787504 -> 2306562789040
	2306562787504 [label=CudnnConvolutionBackward0]
	2306562786544 -> 2306562787504
	2306562786544 [label=SiluBackward0]
	2306562788176 -> 2306562786544
	2306562788176 [label=CudnnBatchNormBackward0]
	2306562789088 -> 2306562788176
	2306562789088 [label=CudnnConvolutionBackward0]
	2306562787216 -> 2306562789088
	2306562787216 [label=SiluBackward0]
	2306562785536 -> 2306562787216
	2306562785536 [label=CudnnBatchNormBackward0]
	2306562801968 -> 2306562785536
	2306562801968 [label=CudnnConvolutionBackward0]
	2306562804368 -> 2306562801968
	2306562804368 [label=SiluBackward0]
	2306562802688 -> 2306562804368
	2306562802688 [label=CudnnBatchNormBackward0]
	2306562802544 -> 2306562802688
	2306562802544 [label=CudnnConvolutionBackward0]
	2306562803168 -> 2306562802544
	2306562803168 [label=SiluBackward0]
	2306562803552 -> 2306562803168
	2306562803552 [label=CudnnBatchNormBackward0]
	2306562803504 -> 2306562803552
	2306562803504 [label=CudnnConvolutionBackward0]
	2306562803888 -> 2306562803504
	2306562803888 [label=SiluBackward0]
	2306562803312 -> 2306562803888
	2306562803312 [label=CudnnBatchNormBackward0]
	2306562804176 -> 2306562803312
	2306562804176 [label=CudnnConvolutionBackward0]
	2306562803216 -> 2306562804176
	2306562803216 [label=CatBackward0]
	2306562803024 -> 2306562803216
	2306562803024 [label=UpsampleNearest2DBackward1]
	2306562802736 -> 2306562803024
	2306562802736 [label=SiluBackward0]
	2306562804800 -> 2306562802736
	2306562804800 [label=CudnnBatchNormBackward0]
	2306562804752 -> 2306562804800
	2306562804752 [label=CudnnConvolutionBackward0]
	2306562805280 -> 2306562804752
	2306562805280 [label=SiluBackward0]
	2306562805472 -> 2306562805280
	2306562805472 [label=CudnnBatchNormBackward0]
	2306562805376 -> 2306562805472
	2306562805376 [label=CudnnConvolutionBackward0]
	2306562805232 -> 2306562805376
	2306562805232 [label=SiluBackward0]
	2306562805520 -> 2306562805232
	2306562805520 [label=CudnnBatchNormBackward0]
	2306562802112 -> 2306562805520
	2306562802112 [label=CudnnConvolutionBackward0]
	2306562802160 -> 2306562802112
	2306562802160 [label=SiluBackward0]
	2306562803360 -> 2306562802160
	2306562803360 [label=CudnnBatchNormBackward0]
	2306562804512 -> 2306562803360
	2306562804512 [label=CudnnConvolutionBackward0]
	2306562804128 -> 2306562804512
	2306562804128 [label=SiluBackward0]
	2306562805664 -> 2306562804128
	2306562805664 [label=CudnnBatchNormBackward0]
	2306562805568 -> 2306562805664
	2306562805568 [label=CudnnConvolutionBackward0]
	2306562804032 -> 2306562805568
	2306562804032 [label=SiluBackward0]
	2306562511488 -> 2306562804032
	2306562511488 [label=CudnnBatchNormBackward0]
	2306562511440 -> 2306562511488
	2306562511440 [label=CudnnConvolutionBackward0]
	2306562514032 -> 2306562511440
	2306562514032 [label=AddBackward0]
	2306562815408 -> 2306562514032
	2306562815408 [label=AddBackward0]
	2306562814400 -> 2306562815408
	2306562814400 [label=AddBackward0]
	2306562816656 -> 2306562814400
	2306562816656 [label=AddBackward0]
	2306562814016 -> 2306562816656
	2306562814016 [label=SiluBackward0]
	2306562814208 -> 2306562814016
	2306562814208 [label=CudnnBatchNormBackward0]
	2306562814112 -> 2306562814208
	2306562814112 [label=CudnnConvolutionBackward0]
	2306562802880 -> 2306562814112
	2306562802880 [label=AddBackward0]
	2306562815792 -> 2306562802880
	2306562815792 [label=AddBackward0]
	2306562815984 -> 2306562815792
	2306562815984 [label=AddBackward0]
	2306562817856 -> 2306562815984
	2306562817856 [label=AddBackward0]
	2306562815360 -> 2306562817856
	2306562815360 [label=AddBackward0]
	2306562816368 -> 2306562815360
	2306562816368 [label=AddBackward0]
	2306562815600 -> 2306562816368
	2306562815600 [label=AddBackward0]
	2306562816800 -> 2306562815600
	2306562816800 [label=AddBackward0]
	2306562815216 -> 2306562816800
	2306562815216 [label=SiluBackward0]
	2306562817232 -> 2306562815216
	2306562817232 [label=CudnnBatchNormBackward0]
	2306562817664 -> 2306562817232
	2306562817664 [label=CudnnConvolutionBackward0]
	2306562787264 -> 2306562817664
	2306562787264 [label=AddBackward0]
	2306562817952 -> 2306562787264
	2306562817952 [label=AddBackward0]
	2306562817712 -> 2306562817952
	2306562817712 [label=AddBackward0]
	2306562816080 -> 2306562817712
	2306562816080 [label=AddBackward0]
	2306910101712 -> 2306562816080
	2306910101712 [label=AddBackward0]
	2306910101856 -> 2306910101712
	2306910101856 [label=AddBackward0]
	2306910102000 -> 2306910101856
	2306910102000 [label=AddBackward0]
	2306910102144 -> 2306910102000
	2306910102144 [label=AddBackward0]
	2306910102288 -> 2306910102144
	2306910102288 [label=SiluBackward0]
	2306910102432 -> 2306910102288
	2306910102432 [label=CudnnBatchNormBackward0]
	2306910102528 -> 2306910102432
	2306910102528 [label=CudnnConvolutionBackward0]
	2306910102720 -> 2306910102528
	2306910102720 [label=AddBackward0]
	2306910102864 -> 2306910102720
	2306910102864 [label=AddBackward0]
	2306910103008 -> 2306910102864
	2306910103008 [label=SiluBackward0]
	2306910103152 -> 2306910103008
	2306910103152 [label=CudnnBatchNormBackward0]
	2306910103248 -> 2306910103152
	2306910103248 [label=CudnnConvolutionBackward0]
	2306910103440 -> 2306910103248
	2306910103440 [label=AddBackward0]
	2306910103584 -> 2306910103440
	2306910103584 [label=SiluBackward0]
	2306910103728 -> 2306910103584
	2306910103728 [label=CudnnBatchNormBackward0]
	2306910103824 -> 2306910103728
	2306910103824 [label=CudnnConvolutionBackward0]
	2306910104016 -> 2306910103824
	2306910104016 [label=SiluBackward0]
	2306910104160 -> 2306910104016
	2306910104160 [label=CudnnBatchNormBackward0]
	2306910104256 -> 2306910104160
	2306910104256 [label=CudnnConvolutionBackward0]
	2306910104448 -> 2306910104256
	2306910104448 [label=ToCopyBackward0]
	2306910104592 -> 2306910104448
	2306909762880 [label="
 (1, 3, 640, 640)" fillcolor=lightblue]
	2306909762880 -> 2306910104592
	2306910104592 [label=AccumulateGrad]
	2306910104400 -> 2306910104256
	2306562584640 [label="model.0.conv.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	2306562584640 -> 2306910104400
	2306910104400 [label=AccumulateGrad]
	2306910104208 -> 2306910104160
	2307422463296 [label="model.0.bn.weight
 (32)" fillcolor=lightblue]
	2307422463296 -> 2306910104208
	2306910104208 [label=AccumulateGrad]
	2306910104064 -> 2306910104160
	2306562587920 [label="model.0.bn.bias
 (32)" fillcolor=lightblue]
	2306562587920 -> 2306910104064
	2306910104064 [label=AccumulateGrad]
	2306910103968 -> 2306910103824
	2306562587840 [label="model.1.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2306562587840 -> 2306910103968
	2306910103968 [label=AccumulateGrad]
	2306910103776 -> 2306910103728
	2306562588480 [label="model.1.bn.weight
 (64)" fillcolor=lightblue]
	2306562588480 -> 2306910103776
	2306910103776 [label=AccumulateGrad]
	2306910103632 -> 2306910103728
	2306562588560 [label="model.1.bn.bias
 (64)" fillcolor=lightblue]
	2306562588560 -> 2306910103632
	2306910103632 [label=AccumulateGrad]
	2306910103536 -> 2306910103440
	2306910103536 [label=SiluBackward0]
	2306910103920 -> 2306910103536
	2306910103920 [label=CudnnBatchNormBackward0]
	2306910104304 -> 2306910103920
	2306910104304 [label=CudnnConvolutionBackward0]
	2306910104544 -> 2306910104304
	2306910104544 [label=SiluBackward0]
	2306910104784 -> 2306910104544
	2306910104784 [label=CudnnBatchNormBackward0]
	2306910104880 -> 2306910104784
	2306910104880 [label=CudnnConvolutionBackward0]
	2306910103584 -> 2306910104880
	2306910105072 -> 2306910104880
	2306562692496 [label="model.2.cv1.conv.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	2306562692496 -> 2306910105072
	2306910105072 [label=AccumulateGrad]
	2306910104832 -> 2306910104784
	2306562691936 [label="model.2.cv1.bn.weight
 (32)" fillcolor=lightblue]
	2306562691936 -> 2306910104832
	2306910104832 [label=AccumulateGrad]
	2306910104496 -> 2306910104784
	2306562691856 [label="model.2.cv1.bn.bias
 (32)" fillcolor=lightblue]
	2306562691856 -> 2306910104496
	2306910104496 [label=AccumulateGrad]
	2306910104688 -> 2306910104304
	2306562692336 [label="model.2.cv2.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2306562692336 -> 2306910104688
	2306910104688 [label=AccumulateGrad]
	2306910104352 -> 2306910103920
	2306562693456 [label="model.2.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2306562693456 -> 2306910104352
	2306910104352 [label=AccumulateGrad]
	2306910103680 -> 2306910103920
	2306562692656 [label="model.2.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2306562692656 -> 2306910103680
	2306910103680 [label=AccumulateGrad]
	2306910103392 -> 2306910103248
	2306562692576 [label="model.3.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2306562692576 -> 2306910103392
	2306910103392 [label=AccumulateGrad]
	2306910103200 -> 2306910103152
	2306562693696 [label="model.3.bn.weight
 (128)" fillcolor=lightblue]
	2306562693696 -> 2306910103200
	2306910103200 [label=AccumulateGrad]
	2306910103056 -> 2306910103152
	2306562693776 [label="model.3.bn.bias
 (128)" fillcolor=lightblue]
	2306562693776 -> 2306910103056
	2306910103056 [label=AccumulateGrad]
	2306910102960 -> 2306910102864
	2306910102960 [label=SiluBackward0]
	2306910103344 -> 2306910102960
	2306910103344 [label=CudnnBatchNormBackward0]
	2306910103872 -> 2306910103344
	2306910103872 [label=CudnnConvolutionBackward0]
	2306910104928 -> 2306910103872
	2306910104928 [label=SiluBackward0]
	2306910105120 -> 2306910104928
	2306910105120 [label=CudnnBatchNormBackward0]
	2306910105216 -> 2306910105120
	2306910105216 [label=CudnnConvolutionBackward0]
	2306910103008 -> 2306910105216
	2306910105408 -> 2306910105216
	2306562694736 [label="model.4.0.cv1.conv.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2306562694736 -> 2306910105408
	2306910105408 [label=AccumulateGrad]
	2306910104976 -> 2306910105120
	2306562694336 [label="model.4.0.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2306562694336 -> 2306910104976
	2306910104976 [label=AccumulateGrad]
	2306910104736 -> 2306910105120
	2306562694016 [label="model.4.0.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2306562694016 -> 2306910104736
	2306910104736 [label=AccumulateGrad]
	2306910105024 -> 2306910103872
	2306562694176 [label="model.4.0.cv2.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2306562694176 -> 2306910105024
	2306910105024 [label=AccumulateGrad]
	2306910104112 -> 2306910103344
	2306562694576 [label="model.4.0.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2306562694576 -> 2306910104112
	2306910104112 [label=AccumulateGrad]
	2306910103104 -> 2306910103344
	2306562692736 [label="model.4.0.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2306562692736 -> 2306910103104
	2306910103104 [label=AccumulateGrad]
	2306910102816 -> 2306910102720
	2306910102816 [label=SiluBackward0]
	2306910103488 -> 2306910102816
	2306910103488 [label=CudnnBatchNormBackward0]
	2306910105360 -> 2306910103488
	2306910105360 [label=CudnnConvolutionBackward0]
	2306910105456 -> 2306910105360
	2306910105456 [label=SiluBackward0]
	2306910105552 -> 2306910105456
	2306910105552 [label=CudnnBatchNormBackward0]
	2306832400448 -> 2306910105552
	2306832400448 [label=CudnnConvolutionBackward0]
	2306910102864 -> 2306832400448
	2306832400736 -> 2306832400448
	2306562692256 [label="model.4.1.cv1.conv.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2306562692256 -> 2306832400736
	2306832400736 [label=AccumulateGrad]
	2306832400496 -> 2306910105552
	2306562694256 [label="model.4.1.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2306562694256 -> 2306832400496
	2306832400496 [label=AccumulateGrad]
	2306832400544 -> 2306910105552
	2306562692896 [label="model.4.1.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2306562692896 -> 2306832400544
	2306832400544 [label=AccumulateGrad]
	2306910105504 -> 2306910105360
	2306562720288 [label="model.4.1.cv2.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2306562720288 -> 2306910105504
	2306910105504 [label=AccumulateGrad]
	2306910104640 -> 2306910103488
	2306562720128 [label="model.4.1.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2306562720128 -> 2306910104640
	2306910104640 [label=AccumulateGrad]
	2306910102912 -> 2306910103488
	2306562720528 [label="model.4.1.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2306562720528 -> 2306910102912
	2306910102912 [label=AccumulateGrad]
	2306910102672 -> 2306910102528
	2306562721488 [label="model.5.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562721488 -> 2306910102672
	2306910102672 [label=AccumulateGrad]
	2306910102480 -> 2306910102432
	2306562720848 [label="model.5.bn.weight
 (256)" fillcolor=lightblue]
	2306562720848 -> 2306910102480
	2306910102480 [label=AccumulateGrad]
	2306910102336 -> 2306910102432
	2306562721088 [label="model.5.bn.bias
 (256)" fillcolor=lightblue]
	2306562721088 -> 2306910102336
	2306910102336 [label=AccumulateGrad]
	2306910102240 -> 2306910102144
	2306910102240 [label=SiluBackward0]
	2306910102624 -> 2306910102240
	2306910102624 [label=CudnnBatchNormBackward0]
	2306910103296 -> 2306910102624
	2306910103296 [label=CudnnConvolutionBackward0]
	2306910105312 -> 2306910103296
	2306910105312 [label=SiluBackward0]
	2306832400784 -> 2306910105312
	2306832400784 [label=CudnnBatchNormBackward0]
	2306832400880 -> 2306832400784
	2306832400880 [label=CudnnConvolutionBackward0]
	2306910102288 -> 2306832400880
	2306832401072 -> 2306832400880
	2306562721648 [label="model.6.0.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562721648 -> 2306832401072
	2306832401072 [label=AccumulateGrad]
	2306832400640 -> 2306832400784
	2306562721568 [label="model.6.0.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562721568 -> 2306832400640
	2306832400640 [label=AccumulateGrad]
	2306832400592 -> 2306832400784
	2306562720688 [label="model.6.0.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562720688 -> 2306832400592
	2306832400592 [label=AccumulateGrad]
	2306910105168 -> 2306910103296
	2306562722688 [label="model.6.0.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562722688 -> 2306910105168
	2306910105168 [label=AccumulateGrad]
	2306910105264 -> 2306910102624
	2306562720608 [label="model.6.0.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562720608 -> 2306910105264
	2306910105264 [label=AccumulateGrad]
	2306910102384 -> 2306910102624
	2306562721008 [label="model.6.0.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562721008 -> 2306910102384
	2306910102384 [label=AccumulateGrad]
	2306910102096 -> 2306910102000
	2306910102096 [label=SiluBackward0]
	2306910102768 -> 2306910102096
	2306910102768 [label=CudnnBatchNormBackward0]
	2306910102192 -> 2306910102768
	2306910102192 [label=CudnnConvolutionBackward0]
	2306832401120 -> 2306910102192
	2306832401120 [label=SiluBackward0]
	2306832401264 -> 2306832401120
	2306832401264 [label=CudnnBatchNormBackward0]
	2306832401360 -> 2306832401264
	2306832401360 [label=CudnnConvolutionBackward0]
	2306910102144 -> 2306832401360
	2306832401552 -> 2306832401360
	2306562721168 [label="model.6.1.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562721168 -> 2306832401552
	2306832401552 [label=AccumulateGrad]
	2306832401312 -> 2306832401264
	2306562721328 [label="model.6.1.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562721328 -> 2306832401312
	2306832401312 [label=AccumulateGrad]
	2306832400976 -> 2306832401264
	2306562723088 [label="model.6.1.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562723088 -> 2306832400976
	2306832400976 [label=AccumulateGrad]
	2306832401168 -> 2306910102192
	2306562723248 [label="model.6.1.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562723248 -> 2306832401168
	2306832401168 [label=AccumulateGrad]
	2306832401024 -> 2306910102768
	2306562722928 [label="model.6.1.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562722928 -> 2306832401024
	2306832401024 [label=AccumulateGrad]
	2306832400688 -> 2306910102768
	2306562723568 [label="model.6.1.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562723568 -> 2306832400688
	2306832400688 [label=AccumulateGrad]
	2306910101952 -> 2306910101856
	2306910101952 [label=SiluBackward0]
	2306910102576 -> 2306910101952
	2306910102576 [label=CudnnBatchNormBackward0]
	2306832401504 -> 2306910102576
	2306832401504 [label=CudnnConvolutionBackward0]
	2306832401600 -> 2306832401504
	2306832401600 [label=SiluBackward0]
	2306832401744 -> 2306832401600
	2306832401744 [label=CudnnBatchNormBackward0]
	2306832401840 -> 2306832401744
	2306832401840 [label=CudnnConvolutionBackward0]
	2306910102000 -> 2306832401840
	2306832402032 -> 2306832401840
	2306562723488 [label="model.6.2.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562723488 -> 2306832402032
	2306832402032 [label=AccumulateGrad]
	2306832401792 -> 2306832401744
	2307152947296 [label="model.6.2.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2307152947296 -> 2306832401792
	2306832401792 [label=AccumulateGrad]
	2306832401456 -> 2306832401744
	2307152947376 [label="model.6.2.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2307152947376 -> 2306832401456
	2306832401456 [label=AccumulateGrad]
	2306832401648 -> 2306832401504
	2306562794176 [label="model.6.2.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562794176 -> 2306832401648
	2306832401648 [label=AccumulateGrad]
	2306832400832 -> 2306910102576
	2306562794096 [label="model.6.2.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562794096 -> 2306832400832
	2306832400832 [label=AccumulateGrad]
	2306832400928 -> 2306910102576
	2306562793696 [label="model.6.2.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562793696 -> 2306832400928
	2306832400928 [label=AccumulateGrad]
	2306910101808 -> 2306910101712
	2306910101808 [label=SiluBackward0]
	2306910102048 -> 2306910101808
	2306910102048 [label=CudnnBatchNormBackward0]
	2306832401984 -> 2306910102048
	2306832401984 [label=CudnnConvolutionBackward0]
	2306832401936 -> 2306832401984
	2306832401936 [label=SiluBackward0]
	2306832402272 -> 2306832401936
	2306832402272 [label=CudnnBatchNormBackward0]
	2306832402368 -> 2306832402272
	2306832402368 [label=CudnnConvolutionBackward0]
	2306910101856 -> 2306832402368
	2306832402560 -> 2306832402368
	2306562794816 [label="model.6.3.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562794816 -> 2306832402560
	2306832402560 [label=AccumulateGrad]
	2306832402320 -> 2306832402272
	2306562794736 [label="model.6.3.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562794736 -> 2306832402320
	2306832402320 [label=AccumulateGrad]
	2306832402176 -> 2306832402272
	2306562795136 [label="model.6.3.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562795136 -> 2306832402176
	2306832402176 [label=AccumulateGrad]
	2306832402080 -> 2306832401984
	2306562795296 [label="model.6.3.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562795296 -> 2306832402080
	2306832402080 [label=AccumulateGrad]
	2306832401216 -> 2306910102048
	2306562794496 [label="model.6.3.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562794496 -> 2306832401216
	2306832401216 [label=AccumulateGrad]
	2306832401408 -> 2306910102048
	2306562794656 [label="model.6.3.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562794656 -> 2306832401408
	2306832401408 [label=AccumulateGrad]
	2306910101664 -> 2306562816080
	2306910101664 [label=SiluBackward0]
	2306910101904 -> 2306910101664
	2306910101904 [label=CudnnBatchNormBackward0]
	2306832402512 -> 2306910101904
	2306832402512 [label=CudnnConvolutionBackward0]
	2306832402608 -> 2306832402512
	2306832402608 [label=SiluBackward0]
	2306832402752 -> 2306832402608
	2306832402752 [label=CudnnBatchNormBackward0]
	2306832402848 -> 2306832402752
	2306832402848 [label=CudnnConvolutionBackward0]
	2306910101712 -> 2306832402848
	2306832403040 -> 2306832402848
	2306562796016 [label="model.6.4.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562796016 -> 2306832403040
	2306832403040 [label=AccumulateGrad]
	2306832402800 -> 2306832402752
	2306562796416 [label="model.6.4.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562796416 -> 2306832402800
	2306832402800 [label=AccumulateGrad]
	2306832402464 -> 2306832402752
	2306562796336 [label="model.6.4.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562796336 -> 2306832402464
	2306832402464 [label=AccumulateGrad]
	2306832402656 -> 2306832402512
	2306562795856 [label="model.6.4.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562795856 -> 2306832402656
	2306832402656 [label=AccumulateGrad]
	2306832401696 -> 2306910101904
	2306562796256 [label="model.6.4.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562796256 -> 2306832401696
	2306832401696 [label=AccumulateGrad]
	2306832401888 -> 2306910101904
	2306562795536 [label="model.6.4.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562795536 -> 2306832401888
	2306832401888 [label=AccumulateGrad]
	2306562816992 -> 2306562817712
	2306562816992 [label=SiluBackward0]
	2306910101760 -> 2306562816992
	2306910101760 [label=CudnnBatchNormBackward0]
	2306832402992 -> 2306910101760
	2306832402992 [label=CudnnConvolutionBackward0]
	2306832403088 -> 2306832402992
	2306832403088 [label=SiluBackward0]
	2306832403232 -> 2306832403088
	2306832403232 [label=CudnnBatchNormBackward0]
	2306832403328 -> 2306832403232
	2306832403328 [label=CudnnConvolutionBackward0]
	2306562816080 -> 2306832403328
	2306832403520 -> 2306832403328
	2306562797296 [label="model.6.5.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562797296 -> 2306832403520
	2306832403520 [label=AccumulateGrad]
	2306832403280 -> 2306832403232
	2306562794336 [label="model.6.5.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562794336 -> 2306832403280
	2306832403280 [label=AccumulateGrad]
	2306832402944 -> 2306832403232
	2306562797216 [label="model.6.5.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562797216 -> 2306832402944
	2306832402944 [label=AccumulateGrad]
	2306832403136 -> 2306832402992
	2306562796576 [label="model.6.5.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562796576 -> 2306832403136
	2306832403136 [label=AccumulateGrad]
	2306832402224 -> 2306910101760
	2306562796896 [label="model.6.5.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562796896 -> 2306832402224
	2306832402224 [label=AccumulateGrad]
	2306832402416 -> 2306910101760
	2306562781248 [label="model.6.5.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562781248 -> 2306832402416
	2306832402416 [label=AccumulateGrad]
	2306562817088 -> 2306562817952
	2306562817088 [label=SiluBackward0]
	2306910101616 -> 2306562817088
	2306910101616 [label=CudnnBatchNormBackward0]
	2306832403472 -> 2306910101616
	2306832403472 [label=CudnnConvolutionBackward0]
	2306832403568 -> 2306832403472
	2306832403568 [label=SiluBackward0]
	2306832403712 -> 2306832403568
	2306832403712 [label=CudnnBatchNormBackward0]
	2306832403808 -> 2306832403712
	2306832403808 [label=CudnnConvolutionBackward0]
	2306562817712 -> 2306832403808
	2306832404000 -> 2306832403808
	2306562782048 [label="model.6.6.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562782048 -> 2306832404000
	2306832404000 [label=AccumulateGrad]
	2306832403760 -> 2306832403712
	2306562781968 [label="model.6.6.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562781968 -> 2306832403760
	2306832403760 [label=AccumulateGrad]
	2306832403424 -> 2306832403712
	2306562782288 [label="model.6.6.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562782288 -> 2306832403424
	2306832403424 [label=AccumulateGrad]
	2306832403616 -> 2306832403472
	2306562782928 [label="model.6.6.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562782928 -> 2306832403616
	2306832403616 [label=AccumulateGrad]
	2306832402704 -> 2306910101616
	2306562782448 [label="model.6.6.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562782448 -> 2306832402704
	2306832402704 [label=AccumulateGrad]
	2306832402896 -> 2306910101616
	2306562782848 [label="model.6.6.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562782848 -> 2306832402896
	2306832402896 [label=AccumulateGrad]
	2306562817520 -> 2306562787264
	2306562817520 [label=SiluBackward0]
	2306910101568 -> 2306562817520
	2306910101568 [label=CudnnBatchNormBackward0]
	2306832403952 -> 2306910101568
	2306832403952 [label=CudnnConvolutionBackward0]
	2306832404048 -> 2306832403952
	2306832404048 [label=SiluBackward0]
	2306832404192 -> 2306832404048
	2306832404192 [label=CudnnBatchNormBackward0]
	2306832404288 -> 2306832404192
	2306832404288 [label=CudnnConvolutionBackward0]
	2306562817952 -> 2306832404288
	2306832404432 -> 2306832404288
	2306562783248 [label="model.6.7.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306562783248 -> 2306832404432
	2306832404432 [label=AccumulateGrad]
	2306832404240 -> 2306832404192
	2306562782608 [label="model.6.7.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306562782608 -> 2306832404240
	2306832404240 [label=AccumulateGrad]
	2306832403904 -> 2306832404192
	2306562783008 [label="model.6.7.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306562783008 -> 2306832403904
	2306832403904 [label=AccumulateGrad]
	2306832404096 -> 2306832403952
	2306562783968 [label="model.6.7.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306562783968 -> 2306832404096
	2306832404096 [label=AccumulateGrad]
	2306832403184 -> 2306910101568
	2306562783888 [label="model.6.7.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306562783888 -> 2306832403184
	2306832403184 [label=AccumulateGrad]
	2306832403376 -> 2306910101568
	2306562784288 [label="model.6.7.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306562784288 -> 2306832403376
	2306832403376 [label=AccumulateGrad]
	2306562817808 -> 2306562817664
	2306562784128 [label="model.7.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562784128 -> 2306562817808
	2306562817808 [label=AccumulateGrad]
	2306562817184 -> 2306562817232
	2306562783648 [label="model.7.bn.weight
 (512)" fillcolor=lightblue]
	2306562783648 -> 2306562817184
	2306562817184 [label=AccumulateGrad]
	2306562817280 -> 2306562817232
	2306562783488 [label="model.7.bn.bias
 (512)" fillcolor=lightblue]
	2306562783488 -> 2306562817280
	2306562817280 [label=AccumulateGrad]
	2306562816704 -> 2306562816800
	2306562816704 [label=SiluBackward0]
	2306562817568 -> 2306562816704
	2306562817568 [label=CudnnBatchNormBackward0]
	2306562817616 -> 2306562817568
	2306562817616 [label=CudnnConvolutionBackward0]
	2306832404336 -> 2306562817616
	2306832404336 [label=SiluBackward0]
	2306832404144 -> 2306832404336
	2306832404144 [label=CudnnBatchNormBackward0]
	2306832445648 -> 2306832404144
	2306832445648 [label=CudnnConvolutionBackward0]
	2306562815216 -> 2306832445648
	2306832445840 -> 2306832445648
	2306562785008 [label="model.8.0.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562785008 -> 2306832445840
	2306832445840 [label=AccumulateGrad]
	2306832445600 -> 2306832404144
	2306562782688 [label="model.8.0.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562782688 -> 2306832445600
	2306832445600 [label=AccumulateGrad]
	2306832445504 -> 2306832404144
	2306562784688 [label="model.8.0.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562784688 -> 2306832445504
	2306832445504 [label=AccumulateGrad]
	2306832404384 -> 2306562817616
	2306562908224 [label="model.8.0.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562908224 -> 2306832404384
	2306832404384 [label=AccumulateGrad]
	2306562817376 -> 2306562817568
	2306562908304 [label="model.8.0.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562908304 -> 2306562817376
	2306562817376 [label=AccumulateGrad]
	2306562817040 -> 2306562817568
	2306562908384 [label="model.8.0.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562908384 -> 2306562817040
	2306562817040 [label=AccumulateGrad]
	2306562814352 -> 2306562815600
	2306562814352 [label=SiluBackward0]
	2306562817424 -> 2306562814352
	2306562817424 [label=CudnnBatchNormBackward0]
	2306832403664 -> 2306562817424
	2306832403664 [label=CudnnConvolutionBackward0]
	2306832445888 -> 2306832403664
	2306832445888 [label=SiluBackward0]
	2306832446032 -> 2306832445888
	2306832446032 [label=CudnnBatchNormBackward0]
	2306832446128 -> 2306832446032
	2306832446128 [label=CudnnConvolutionBackward0]
	2306562816800 -> 2306832446128
	2306832446320 -> 2306832446128
	2306562908784 [label="model.8.1.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562908784 -> 2306832446320
	2306832446320 [label=AccumulateGrad]
	2306832446080 -> 2306832446032
	2306562908864 [label="model.8.1.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562908864 -> 2306832446080
	2306832446080 [label=AccumulateGrad]
	2306832445744 -> 2306832446032
	2306562908944 [label="model.8.1.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562908944 -> 2306832445744
	2306832445744 [label=AccumulateGrad]
	2306832445936 -> 2306832403664
	2306562909344 [label="model.8.1.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562909344 -> 2306832445936
	2306832445936 [label=AccumulateGrad]
	2306832403856 -> 2306562817424
	2306562909424 [label="model.8.1.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562909424 -> 2306832403856
	2306832403856 [label=AccumulateGrad]
	2306832445792 -> 2306562817424
	2306562909504 [label="model.8.1.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562909504 -> 2306832445792
	2306832445792 [label=AccumulateGrad]
	2306562814880 -> 2306562816368
	2306562814880 [label=SiluBackward0]
	2306562814736 -> 2306562814880
	2306562814736 [label=CudnnBatchNormBackward0]
	2306832446272 -> 2306562814736
	2306832446272 [label=CudnnConvolutionBackward0]
	2306832446368 -> 2306832446272
	2306832446368 [label=SiluBackward0]
	2306832446512 -> 2306832446368
	2306832446512 [label=CudnnBatchNormBackward0]
	2306832446608 -> 2306832446512
	2306832446608 [label=CudnnConvolutionBackward0]
	2306562815600 -> 2306832446608
	2306832446800 -> 2306832446608
	2306562909904 [label="model.8.2.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562909904 -> 2306832446800
	2306832446800 [label=AccumulateGrad]
	2306832446560 -> 2306832446512
	2306562909984 [label="model.8.2.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562909984 -> 2306832446560
	2306832446560 [label=AccumulateGrad]
	2306832446224 -> 2306832446512
	2306562910064 [label="model.8.2.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562910064 -> 2306832446224
	2306832446224 [label=AccumulateGrad]
	2306832446416 -> 2306832446272
	2306562910464 [label="model.8.2.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562910464 -> 2306832446416
	2306832446416 [label=AccumulateGrad]
	2306832445552 -> 2306562814736
	2306562910544 [label="model.8.2.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562910544 -> 2306832445552
	2306832445552 [label=AccumulateGrad]
	2306832445696 -> 2306562814736
	2306562910624 [label="model.8.2.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562910624 -> 2306832445696
	2306832445696 [label=AccumulateGrad]
	2306562815648 -> 2306562815360
	2306562815648 [label=SiluBackward0]
	2306562815024 -> 2306562815648
	2306562815024 [label=CudnnBatchNormBackward0]
	2306832446752 -> 2306562815024
	2306832446752 [label=CudnnConvolutionBackward0]
	2306832446848 -> 2306832446752
	2306832446848 [label=SiluBackward0]
	2306832446992 -> 2306832446848
	2306832446992 [label=CudnnBatchNormBackward0]
	2306832447088 -> 2306832446992
	2306832447088 [label=CudnnConvolutionBackward0]
	2306562816368 -> 2306832447088
	2306832447280 -> 2306832447088
	2306562911024 [label="model.8.3.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562911024 -> 2306832447280
	2306832447280 [label=AccumulateGrad]
	2306832447040 -> 2306832446992
	2306562911104 [label="model.8.3.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562911104 -> 2306832447040
	2306832447040 [label=AccumulateGrad]
	2306832446704 -> 2306832446992
	2306562911184 [label="model.8.3.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562911184 -> 2306832446704
	2306832446704 [label=AccumulateGrad]
	2306832446896 -> 2306832446752
	2306562911584 [label="model.8.3.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562911584 -> 2306832446896
	2306832446896 [label=AccumulateGrad]
	2306832445984 -> 2306562815024
	2306562911664 [label="model.8.3.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562911664 -> 2306832445984
	2306832445984 [label=AccumulateGrad]
	2306832446176 -> 2306562815024
	2306562911744 [label="model.8.3.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562911744 -> 2306832446176
	2306832446176 [label=AccumulateGrad]
	2306562814976 -> 2306562817856
	2306562814976 [label=SiluBackward0]
	2306562816320 -> 2306562814976
	2306562816320 [label=CudnnBatchNormBackward0]
	2306832447232 -> 2306562816320
	2306832447232 [label=CudnnConvolutionBackward0]
	2306832447328 -> 2306832447232
	2306832447328 [label=SiluBackward0]
	2306832447472 -> 2306832447328
	2306832447472 [label=CudnnBatchNormBackward0]
	2306832447568 -> 2306832447472
	2306832447568 [label=CudnnConvolutionBackward0]
	2306562815360 -> 2306832447568
	2306832447760 -> 2306832447568
	2306562912144 [label="model.8.4.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562912144 -> 2306832447760
	2306832447760 [label=AccumulateGrad]
	2306832447520 -> 2306832447472
	2306562990144 [label="model.8.4.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562990144 -> 2306832447520
	2306832447520 [label=AccumulateGrad]
	2306832447184 -> 2306832447472
	2306562990224 [label="model.8.4.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562990224 -> 2306832447184
	2306832447184 [label=AccumulateGrad]
	2306832447376 -> 2306832447232
	2306562990624 [label="model.8.4.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562990624 -> 2306832447376
	2306832447376 [label=AccumulateGrad]
	2306832446464 -> 2306562816320
	2306562990704 [label="model.8.4.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562990704 -> 2306832446464
	2306832446464 [label=AccumulateGrad]
	2306832446656 -> 2306562816320
	2306562990784 [label="model.8.4.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562990784 -> 2306832446656
	2306832446656 [label=AccumulateGrad]
	2306562816128 -> 2306562815984
	2306562816128 [label=SiluBackward0]
	2306562816464 -> 2306562816128
	2306562816464 [label=CudnnBatchNormBackward0]
	2306832447712 -> 2306562816464
	2306832447712 [label=CudnnConvolutionBackward0]
	2306832447808 -> 2306832447712
	2306832447808 [label=SiluBackward0]
	2306832447952 -> 2306832447808
	2306832447952 [label=CudnnBatchNormBackward0]
	2306832448048 -> 2306832447952
	2306832448048 [label=CudnnConvolutionBackward0]
	2306562817856 -> 2306832448048
	2306832448240 -> 2306832448048
	2306562991184 [label="model.8.5.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562991184 -> 2306832448240
	2306832448240 [label=AccumulateGrad]
	2306832448000 -> 2306832447952
	2306562991264 [label="model.8.5.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562991264 -> 2306832448000
	2306832448000 [label=AccumulateGrad]
	2306832447664 -> 2306832447952
	2306562991344 [label="model.8.5.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562991344 -> 2306832447664
	2306832447664 [label=AccumulateGrad]
	2306832447856 -> 2306832447712
	2306562991744 [label="model.8.5.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562991744 -> 2306832447856
	2306832447856 [label=AccumulateGrad]
	2306832446944 -> 2306562816464
	2306562991824 [label="model.8.5.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562991824 -> 2306832446944
	2306832446944 [label=AccumulateGrad]
	2306832447136 -> 2306562816464
	2306562991904 [label="model.8.5.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562991904 -> 2306832447136
	2306832447136 [label=AccumulateGrad]
	2306562816224 -> 2306562815792
	2306562816224 [label=SiluBackward0]
	2306562816512 -> 2306562816224
	2306562816512 [label=CudnnBatchNormBackward0]
	2306832448192 -> 2306562816512
	2306832448192 [label=CudnnConvolutionBackward0]
	2306832448288 -> 2306832448192
	2306832448288 [label=SiluBackward0]
	2306832448432 -> 2306832448288
	2306832448432 [label=CudnnBatchNormBackward0]
	2306832448528 -> 2306832448432
	2306832448528 [label=CudnnConvolutionBackward0]
	2306562815984 -> 2306832448528
	2306832448720 -> 2306832448528
	2306562992304 [label="model.8.6.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562992304 -> 2306832448720
	2306832448720 [label=AccumulateGrad]
	2306832448480 -> 2306832448432
	2306562992384 [label="model.8.6.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562992384 -> 2306832448480
	2306832448480 [label=AccumulateGrad]
	2306832448144 -> 2306832448432
	2306562992464 [label="model.8.6.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562992464 -> 2306832448144
	2306832448144 [label=AccumulateGrad]
	2306832448336 -> 2306832448192
	2306562992864 [label="model.8.6.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562992864 -> 2306832448336
	2306832448336 [label=AccumulateGrad]
	2306832447424 -> 2306562816512
	2306562992944 [label="model.8.6.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562992944 -> 2306832447424
	2306832447424 [label=AccumulateGrad]
	2306832447616 -> 2306562816512
	2306562993024 [label="model.8.6.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306562993024 -> 2306832447616
	2306832447616 [label=AccumulateGrad]
	2306562815840 -> 2306562802880
	2306562815840 [label=SiluBackward0]
	2306562816176 -> 2306562815840
	2306562816176 [label=CudnnBatchNormBackward0]
	2306832448672 -> 2306562816176
	2306832448672 [label=CudnnConvolutionBackward0]
	2306832448768 -> 2306832448672
	2306832448768 [label=SiluBackward0]
	2306832448912 -> 2306832448768
	2306832448912 [label=CudnnBatchNormBackward0]
	2306832449008 -> 2306832448912
	2306832449008 [label=CudnnConvolutionBackward0]
	2306562815792 -> 2306832449008
	2306832449200 -> 2306832449008
	2306562993424 [label="model.8.7.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306562993424 -> 2306832449200
	2306832449200 [label=AccumulateGrad]
	2306832448960 -> 2306832448912
	2306562993504 [label="model.8.7.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306562993504 -> 2306832448960
	2306832448960 [label=AccumulateGrad]
	2306832448624 -> 2306832448912
	2306562993584 [label="model.8.7.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306562993584 -> 2306832448624
	2306832448624 [label=AccumulateGrad]
	2306832448816 -> 2306832448672
	2306562993984 [label="model.8.7.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306562993984 -> 2306832448816
	2306832448816 [label=AccumulateGrad]
	2306832447904 -> 2306562816176
	2306562994064 [label="model.8.7.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306562994064 -> 2306832447904
	2306832447904 [label=AccumulateGrad]
	2306832448096 -> 2306562816176
	2306563084352 [label="model.8.7.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306563084352 -> 2306832448096
	2306832448096 [label=AccumulateGrad]
	2306562815552 -> 2306562814112
	2306563084992 [label="model.9.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306563084992 -> 2306562815552
	2306562815552 [label=AccumulateGrad]
	2306562814640 -> 2306562814208
	2306563084752 [label="model.9.bn.weight
 (1024)" fillcolor=lightblue]
	2306563084752 -> 2306562814640
	2306562814640 [label=AccumulateGrad]
	2306562815120 -> 2306562814208
	2306563084832 [label="model.9.bn.bias
 (1024)" fillcolor=lightblue]
	2306563084832 -> 2306562815120
	2306562815120 [label=AccumulateGrad]
	2306562814544 -> 2306562816656
	2306562814544 [label=SiluBackward0]
	2306562815456 -> 2306562814544
	2306562815456 [label=CudnnBatchNormBackward0]
	2306562816032 -> 2306562815456
	2306562816032 [label=CudnnConvolutionBackward0]
	2306832449056 -> 2306562816032
	2306832449056 [label=SiluBackward0]
	2306832449248 -> 2306832449056
	2306832449248 [label=CudnnBatchNormBackward0]
	2306832449344 -> 2306832449248
	2306832449344 [label=CudnnConvolutionBackward0]
	2306562814016 -> 2306832449344
	2306832449488 -> 2306832449344
	2306563085632 [label="model.10.0.cv1.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306563085632 -> 2306832449488
	2306832449488 [label=AccumulateGrad]
	2306832449104 -> 2306832449248
	2306563085472 [label="model.10.0.cv1.bn.weight
 (512)" fillcolor=lightblue]
	2306563085472 -> 2306832449104
	2306832449104 [label=AccumulateGrad]
	2306832448864 -> 2306832449248
	2306563085392 [label="model.10.0.cv1.bn.bias
 (512)" fillcolor=lightblue]
	2306563085392 -> 2306832448864
	2306832448864 [label=AccumulateGrad]
	2306832449152 -> 2306562816032
	2306563086032 [label="model.10.0.cv2.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306563086032 -> 2306832449152
	2306832449152 [label=AccumulateGrad]
	2306562815744 -> 2306562815456
	2306563086112 [label="model.10.0.cv2.bn.weight
 (1024)" fillcolor=lightblue]
	2306563086112 -> 2306562815744
	2306562815744 [label=AccumulateGrad]
	2306562814064 -> 2306562815456
	2306563086192 [label="model.10.0.cv2.bn.bias
 (1024)" fillcolor=lightblue]
	2306563086192 -> 2306562814064
	2306562814064 [label=AccumulateGrad]
	2306562814784 -> 2306562814400
	2306562814784 [label=SiluBackward0]
	2306562814928 -> 2306562814784
	2306562814928 [label=CudnnBatchNormBackward0]
	2306832449440 -> 2306562814928
	2306832449440 [label=CudnnConvolutionBackward0]
	2306832449296 -> 2306832449440
	2306832449296 [label=SiluBackward0]
	2306832482608 -> 2306832449296
	2306832482608 [label=CudnnBatchNormBackward0]
	2306832482704 -> 2306832482608
	2306832482704 [label=CudnnConvolutionBackward0]
	2306562816656 -> 2306832482704
	2306832482896 -> 2306832482704
	2306563086592 [label="model.10.1.cv1.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306563086592 -> 2306832482896
	2306832482896 [label=AccumulateGrad]
	2306832482656 -> 2306832482608
	2306563086672 [label="model.10.1.cv1.bn.weight
 (512)" fillcolor=lightblue]
	2306563086672 -> 2306832482656
	2306832482656 [label=AccumulateGrad]
	2306832482416 -> 2306832482608
	2306563086752 [label="model.10.1.cv1.bn.bias
 (512)" fillcolor=lightblue]
	2306563086752 -> 2306832482416
	2306832482416 [label=AccumulateGrad]
	2306832482464 -> 2306832449440
	2306563087152 [label="model.10.1.cv2.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306563087152 -> 2306832482464
	2306832482464 [label=AccumulateGrad]
	2306832448384 -> 2306562814928
	2306563087232 [label="model.10.1.cv2.bn.weight
 (1024)" fillcolor=lightblue]
	2306563087232 -> 2306832448384
	2306832448384 [label=AccumulateGrad]
	2306832448576 -> 2306562814928
	2306563087312 [label="model.10.1.cv2.bn.bias
 (1024)" fillcolor=lightblue]
	2306563087312 -> 2306832448576
	2306832448576 [label=AccumulateGrad]
	2306562814448 -> 2306562815408
	2306562814448 [label=SiluBackward0]
	2306832449392 -> 2306562814448
	2306832449392 [label=CudnnBatchNormBackward0]
	2306562814832 -> 2306832449392
	2306562814832 [label=CudnnConvolutionBackward0]
	2306832482944 -> 2306562814832
	2306832482944 [label=SiluBackward0]
	2306832483088 -> 2306832482944
	2306832483088 [label=CudnnBatchNormBackward0]
	2306832483184 -> 2306832483088
	2306832483184 [label=CudnnConvolutionBackward0]
	2306562814400 -> 2306832483184
	2306832483376 -> 2306832483184
	2306563087712 [label="model.10.2.cv1.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306563087712 -> 2306832483376
	2306832483376 [label=AccumulateGrad]
	2306832483136 -> 2306832483088
	2306563087792 [label="model.10.2.cv1.bn.weight
 (512)" fillcolor=lightblue]
	2306563087792 -> 2306832483136
	2306832483136 [label=AccumulateGrad]
	2306832482800 -> 2306832483088
	2306563087872 [label="model.10.2.cv1.bn.bias
 (512)" fillcolor=lightblue]
	2306563087872 -> 2306832482800
	2306832482800 [label=AccumulateGrad]
	2306832482992 -> 2306562814832
	2306563088272 [label="model.10.2.cv2.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306563088272 -> 2306832482992
	2306832482992 [label=AccumulateGrad]
	2306832482848 -> 2306832449392
	2306909667392 [label="model.10.2.cv2.bn.weight
 (1024)" fillcolor=lightblue]
	2306909667392 -> 2306832482848
	2306832482848 [label=AccumulateGrad]
	2306832482512 -> 2306832449392
	2306909667472 [label="model.10.2.cv2.bn.bias
 (1024)" fillcolor=lightblue]
	2306909667472 -> 2306832482512
	2306832482512 [label=AccumulateGrad]
	2306562815312 -> 2306562514032
	2306562815312 [label=SiluBackward0]
	2306562816752 -> 2306562815312
	2306562816752 [label=CudnnBatchNormBackward0]
	2306832483328 -> 2306562816752
	2306832483328 [label=CudnnConvolutionBackward0]
	2306832483424 -> 2306832483328
	2306832483424 [label=SiluBackward0]
	2306832483568 -> 2306832483424
	2306832483568 [label=CudnnBatchNormBackward0]
	2306832483664 -> 2306832483568
	2306832483664 [label=CudnnConvolutionBackward0]
	2306562815408 -> 2306832483664
	2306832483856 -> 2306832483664
	2306909667872 [label="model.10.3.cv1.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306909667872 -> 2306832483856
	2306832483856 [label=AccumulateGrad]
	2306832483616 -> 2306832483568
	2306909667952 [label="model.10.3.cv1.bn.weight
 (512)" fillcolor=lightblue]
	2306909667952 -> 2306832483616
	2306832483616 [label=AccumulateGrad]
	2306832483280 -> 2306832483568
	2306909668032 [label="model.10.3.cv1.bn.bias
 (512)" fillcolor=lightblue]
	2306909668032 -> 2306832483280
	2306832483280 [label=AccumulateGrad]
	2306832483472 -> 2306832483328
	2306909668432 [label="model.10.3.cv2.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306909668432 -> 2306832483472
	2306832483472 [label=AccumulateGrad]
	2306832482560 -> 2306562816752
	2306562784848 [label="model.10.3.cv2.bn.weight
 (1024)" fillcolor=lightblue]
	2306562784848 -> 2306832482560
	2306832482560 [label=AccumulateGrad]
	2306832482752 -> 2306562816752
	2307281390464 [label="model.10.3.cv2.bn.bias
 (1024)" fillcolor=lightblue]
	2307281390464 -> 2306832482752
	2306832482752 [label=AccumulateGrad]
	2306562814256 -> 2306562511440
	2306909668672 [label="model.11.cv1.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306909668672 -> 2306562814256
	2306562814256 [label=AccumulateGrad]
	2306562513216 -> 2306562511488
	2306909668352 [label="model.11.cv1.bn.weight
 (512)" fillcolor=lightblue]
	2306909668352 -> 2306562513216
	2306562513216 [label=AccumulateGrad]
	2306562511344 -> 2306562511488
	2306909668592 [label="model.11.cv1.bn.bias
 (512)" fillcolor=lightblue]
	2306909668592 -> 2306562511344
	2306562511344 [label=AccumulateGrad]
	2306562511584 -> 2306562805568
	2306909669072 [label="model.11.cv2.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306909669072 -> 2306562511584
	2306562511584 [label=AccumulateGrad]
	2306562804416 -> 2306562805664
	2306909669152 [label="model.11.cv2.bn.weight
 (1024)" fillcolor=lightblue]
	2306909669152 -> 2306562804416
	2306562804416 [label=AccumulateGrad]
	2306562805040 -> 2306562805664
	2306909669232 [label="model.11.cv2.bn.bias
 (1024)" fillcolor=lightblue]
	2306909669232 -> 2306562805040
	2306562805040 [label=AccumulateGrad]
	2306562804896 -> 2306562804512
	2306909669952 [label="model.12.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306909669952 -> 2306562804896
	2306562804896 [label=AccumulateGrad]
	2306562804272 -> 2306562803360
	2306909669712 [label="model.12.bn.weight
 (512)" fillcolor=lightblue]
	2306909669712 -> 2306562804272
	2306562804272 [label=AccumulateGrad]
	2306562803792 -> 2306562803360
	2306909669872 [label="model.12.bn.bias
 (512)" fillcolor=lightblue]
	2306909669872 -> 2306562803792
	2306562803792 [label=AccumulateGrad]
	2306562802976 -> 2306562802112
	2306909670672 [label="model.13.conv.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2306909670672 -> 2306562802976
	2306562802976 [label=AccumulateGrad]
	2306562802592 -> 2306562805520
	2306909670432 [label="model.13.bn.weight
 (1024)" fillcolor=lightblue]
	2306909670432 -> 2306562802592
	2306562802592 [label=AccumulateGrad]
	2306562804608 -> 2306562805520
	2306909670592 [label="model.13.bn.bias
 (1024)" fillcolor=lightblue]
	2306909670592 -> 2306562804608
	2306562804608 [label=AccumulateGrad]
	2306562805328 -> 2306562805376
	2306909761680 [label="model.14.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2306909761680 -> 2306562805328
	2306562805328 [label=AccumulateGrad]
	2306562805424 -> 2306562805472
	2306909671072 [label="model.14.bn.weight
 (512)" fillcolor=lightblue]
	2306909671072 -> 2306562805424
	2306562805424 [label=AccumulateGrad]
	2306562805088 -> 2306562805472
	2306909671312 [label="model.14.bn.bias
 (512)" fillcolor=lightblue]
	2306909671312 -> 2306562805088
	2306562805088 [label=AccumulateGrad]
	2306562804656 -> 2306562804752
	2306909763040 [label="model.16.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306909763040 -> 2306562804656
	2306562804656 [label=AccumulateGrad]
	2306562804560 -> 2306562804800
	2306909762800 [label="model.16.bn.weight
 (256)" fillcolor=lightblue]
	2306909762800 -> 2306562804560
	2306562804560 [label=AccumulateGrad]
	2306562802784 -> 2306562804800
	2306909762960 [label="model.16.bn.bias
 (256)" fillcolor=lightblue]
	2306909762960 -> 2306562802784
	2306562802784 [label=AccumulateGrad]
	2306562802880 -> 2306562803216
	2306562803984 -> 2306562804176
	2306909763920 [label="model.19.cv1.conv.weight
 (256, 768, 1, 1)" fillcolor=lightblue]
	2306909763920 -> 2306562803984
	2306562803984 [label=AccumulateGrad]
	2306562802016 -> 2306562803312
	2306909763840 [label="model.19.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306909763840 -> 2306562802016
	2306562802016 [label=AccumulateGrad]
	2306562803840 -> 2306562803312
	2306909763600 [label="model.19.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306909763600 -> 2306562803840
	2306562803840 [label=AccumulateGrad]
	2306562803648 -> 2306562803504
	2306909764320 [label="model.19.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306909764320 -> 2306562803648
	2306562803648 [label=AccumulateGrad]
	2306562803264 -> 2306562803552
	2306909764400 [label="model.19.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306909764400 -> 2306562803264
	2306562803264 [label=AccumulateGrad]
	2306562803120 -> 2306562803552
	2306909764480 [label="model.19.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306909764480 -> 2306562803120
	2306562803120 [label=AccumulateGrad]
	2306562801776 -> 2306562802544
	2306909765120 [label="model.20.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306909765120 -> 2306562801776
	2306562801776 [label=AccumulateGrad]
	2306562802400 -> 2306562802688
	2306909764960 [label="model.20.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2306909764960 -> 2306562802400
	2306562802400 [label=AccumulateGrad]
	2306562804464 -> 2306562802688
	2306909764880 [label="model.20.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2306909764880 -> 2306562804464
	2306562804464 [label=AccumulateGrad]
	2306562802304 -> 2306562801968
	2306909765520 [label="model.20.cv2.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2306909765520 -> 2306562802304
	2306562802304 [label=AccumulateGrad]
	2306562802208 -> 2306562785536
	2306909859904 [label="model.20.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2306909859904 -> 2306562802208
	2306562802208 [label=AccumulateGrad]
	2306562802832 -> 2306562785536
	2306909859984 [label="model.20.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2306909859984 -> 2306562802832
	2306562802832 [label=AccumulateGrad]
	2306562787072 -> 2306562789088
	2306909860624 [label="model.21.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2306909860624 -> 2306562787072
	2306562787072 [label=AccumulateGrad]
	2306562788800 -> 2306562788176
	2306909860544 [label="model.21.bn.weight
 (256)" fillcolor=lightblue]
	2306909860544 -> 2306562788800
	2306562788800 [label=AccumulateGrad]
	2306562788848 -> 2306562788176
	2306909860704 [label="model.21.bn.bias
 (256)" fillcolor=lightblue]
	2306909860704 -> 2306562788848
	2306562788848 [label=AccumulateGrad]
	2306562788560 -> 2306562787504
	2306909862144 [label="model.23.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306909862144 -> 2306562788560
	2306562788560 [label=AccumulateGrad]
	2306562787024 -> 2306562789040
	2306909861904 [label="model.23.bn.weight
 (128)" fillcolor=lightblue]
	2306909861904 -> 2306562787024
	2306562787024 [label=AccumulateGrad]
	2306562789280 -> 2306562789040
	2306909862064 [label="model.23.bn.bias
 (128)" fillcolor=lightblue]
	2306909862064 -> 2306562789280
	2306562789280 [label=AccumulateGrad]
	2306562787264 -> 2306562786352
	2306562787744 -> 2306562785872
	2306909863104 [label="model.26.cv1.conv.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2306909863104 -> 2306562787744
	2306562787744 [label=AccumulateGrad]
	2306562787888 -> 2306562787936
	2306909862944 [label="model.26.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306909862944 -> 2306562787888
	2306562787888 [label=AccumulateGrad]
	2306562787792 -> 2306562787936
	2306909863184 [label="model.26.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306909863184 -> 2306562787792
	2306562787792 [label=AccumulateGrad]
	2306562788656 -> 2306562786784
	2306909863504 [label="model.26.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306909863504 -> 2306562788656
	2306562788656 [label=AccumulateGrad]
	2306562788368 -> 2306562788416
	2306909863584 [label="model.26.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306909863584 -> 2306562788368
	2306562788368 [label=AccumulateGrad]
	2306562788464 -> 2306562788416
	2306909863664 [label="model.26.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306909863664 -> 2306562788464
	2306562788464 [label=AccumulateGrad]
	2306562788032 -> 2306562787600
	2306909930016 [label="model.27.0.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306909930016 -> 2306562788032
	2306562788032 [label=AccumulateGrad]
	2306562787648 -> 2306562787696
	2306909929776 [label="model.27.0.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306909929776 -> 2306562787648
	2306562787648 [label=AccumulateGrad]
	2306562785440 -> 2306562787696
	2306909929936 [label="model.27.0.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306909929936 -> 2306562785440
	2306562785440 [label=AccumulateGrad]
	2306562786592 -> 2306562785968
	2306909930416 [label="model.27.0.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306909930416 -> 2306562786592
	2306562786592 [label=AccumulateGrad]
	2306562786400 -> 2306562786016
	2306909930496 [label="model.27.0.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306909930496 -> 2306562786400
	2306562786400 [label=AccumulateGrad]
	2306562786640 -> 2306562786016
	2306909930576 [label="model.27.0.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306909930576 -> 2306562786640
	2306562786640 [label=AccumulateGrad]
	2306562786688 -> 2306562787120
	2306909930976 [label="model.27.1.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2306909930976 -> 2306562786688
	2306562786688 [label=AccumulateGrad]
	2306562786208 -> 2306562788992
	2306909931056 [label="model.27.1.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2306909931056 -> 2306562786208
	2306562786208 [label=AccumulateGrad]
	2306562786832 -> 2306562788992
	2306909931136 [label="model.27.1.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2306909931136 -> 2306562786832
	2306562786832 [label=AccumulateGrad]
	2306562786928 -> 2306562786064
	2306909931536 [label="model.27.1.cv2.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2306909931536 -> 2306562786928
	2306562786928 [label=AccumulateGrad]
	2306562786112 -> 2306562785776
	2306909931616 [label="model.27.1.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2306909931616 -> 2306562786112
	2306562786112 [label=AccumulateGrad]
	2306562785488 -> 2306562785776
	2306909931696 [label="model.27.1.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2306909931696 -> 2306562785488
	2306562785488 [label=AccumulateGrad]
	2306562787456 -> 2306562739840
	2306909932736 [label="model.28.m.0.weight
 (255, 256, 1, 1)" fillcolor=lightblue]
	2306909932736 -> 2306562787456
	2306562787456 [label=AccumulateGrad]
	2306562785728 -> 2306562736816
	2306562785728 [label=ReshapeAliasBackward0]
	2306562786496 -> 2306562785728
	2306562692976 [label="model.28.m.0.bias
 (255)" fillcolor=lightblue]
	2306562692976 -> 2306562786496
	2306562786496 [label=AccumulateGrad]
	2306562739312 -> 2306910030640
}
